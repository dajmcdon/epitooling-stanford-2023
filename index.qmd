---
format: 
  revealjs:
    footer: "`{epiprocess}` [&]{.primary} `{epipredict}` --- [dajmcdon.github.io/epitooling-stanford-2023]{.smaller}"
    logo: "gfx/delphi.jpg"
    embed-resources: true
    width: 1280
    height: 720
    theme: [default, themer.scss]
    fig-format: svg
execute: 
  cache: true
editor: source
---

```{r}
#| fig-align: center
#| fig-format: svg
primary <- "#a8201a"
secondary <- "#f9c80e"
tertiary <- "#2a76dd"
fourth_colour <- "#311847"
library(epiprocess)
suppressMessages(library(tidyverse))
x <- archive_cases_dv_subset
x_latest <- epix_as_of(x, max_version = max(x$DT$version))
self_max = max(x$DT$version)
versions = seq(as.Date("2020-06-01"), self_max - 1, by = "1 month")
snapshots_all <- map_dfr(versions, function(v) { 
  epix_as_of(x, max_version = v) %>% mutate(version = v)}) %>%
  bind_rows(x_latest %>% mutate(version = self_max)) %>%
  mutate(latest = version == self_max)
snapshots <- snapshots_all %>% 
  filter(geo_value %in% c("ca", "fl"))
```

```{r}
#| include: false
#| label: cover-art
ggplot(snapshots_all %>% 
         arrange(geo_value, version, time_value) %>% 
         filter(!latest),
       aes(x = time_value, y = percent_cli)) +  
  geom_line(aes(color = factor(version), group = interaction(geo_value, version))) + 
  #geom_vline(aes(color = factor(version), xintercept = version), lty = 3, 
  #           size = 0.5) +
  scale_x_date(minor_breaks = "month", labels = NULL) +
  labs(x = "", y = "") + 
  theme_void() +
  coord_cartesian(xlim = as.Date(c("2020-10-01", NA)), ylim = c(-5, NA)) +
  scale_color_viridis_d(option = "B", end = .8) +
  theme(legend.position = "none", panel.background = element_blank()) +
  geom_line(
    data = snapshots %>% filter(latest),
    aes(x = time_value, y = percent_cli, group = geo_value), 
    inherit.aes = FALSE, color = "black")
```



:::: {.columns}
::: {.column width="20%"}

:::
::: {.column width="80%"}
## `{epiprocess}` & `{epipredict}` {background-image="index_files/figure-revealjs/cover-art-1.svg" background-position="bottom"}

### `R` packages to ramp up forecasting systems

<br>

#### Daniel J. McDonald, Ryan J. Tibshirani, Logan C. Brooks 
#### and CMU's Delphi Group

Stanford STATS/BIODS 352 --- 12 April 2023
:::
::::

## Background

* Covid-19 Pandemic required quickly implementing forecasting systems.

* Basic processing---[outlier detection]{.primary}, [reporting issues]{.secondary}, [geographic granularity]{.tertiary}---implemented in parallel / error prone

* Data revisions complicate evaluation

* Simple models often outperformed complicated ones

* Custom software not easily adapted / improved by other groups

* Hard for public health actors to borrow / customize community techniques


## `{epiprocess}` 
### Basic processing operations and data structures

* General EDA for "panel data"
* Calculate rolling statistics
* Fill / impute gaps
* Examine correlations
* Store revision history smartly
* Inspect revision patterns
* Find / correct outliers

## `{epiprocess}` Data Structures

### `epi_df`: snapshot of a data set

* a tibble with a couple of
required columns, `geo_value` and `time_value`.
* arbitrary additional columns containing "measured" values, called "signals"
* additional "keys" that index subsets (`age_group`, `ethnicity`, etc.)

::: {.callout-note}
## `epi_df`

Represents a [snapshot]{.primary} that
contains the most [up-to-date values]{.primary} of the signal variables, [as of]{.primary} a given time.
:::

## `{epiprocess}` Data Structures

### `epi_archive`: collection of `epi_df`s

* full version history of a data set
* acts like a bunch of `epi_df`s
* but stored "compactly"
* Allows you to do things you would do on an `epi_df` but based on the data that "would have been available at the time"

::: {.callout-note}
## Revisions

Epidemiology data gets revised frequently. (Happens in Economics as well.) 

* We may want to use the data "as it looked in the past" 
* or we may want to examine "the history of revisions".
:::


## Revision patterns

```{r}
ggplot(snapshots %>% filter(!latest),
            aes(x = time_value, y = percent_cli)) +  
  geom_line(aes(color = factor(version))) + 
  geom_vline(aes(color = factor(version), xintercept = version), lty = 3) +
  facet_wrap(~ geo_value, scales = "free_y", nrow = 1) +
  scale_x_date(minor_breaks = "month", date_labels = "%b %Y") +
  labs(x = "", y = "% of doctor's visits with\n Covid-like illness") + 
  theme_bw(base_size = 24) +
  scale_color_viridis_d(option = "B", end = .8) +
  theme(legend.position = "none") +
  geom_line(data = snapshots %>% filter(latest),
               aes(x = time_value, y = percent_cli), 
               inherit.aes = FALSE, color = "black")
```

## Simple sliding computations

```{r, echo=TRUE}
dav14 <- jhu_csse_daily_subset %>%
  group_by(geo_value) %>%
  epi_slide(cases_14dav = mean(cases), n = 14)
```

```{r, fig.align='center'}
dav14 %>%
  ggplot(aes(x = time_value)) +
  geom_col(aes(y = cases / 1000, fill = geo_value), alpha = 0.5, show.legend = FALSE) +
  geom_line(aes(y = cases_14dav / 1000, col = geo_value), show.legend = FALSE) +
  facet_wrap(~ geo_value, scales = "free_y") +
  theme_bw(base_size = 24) +
  scale_color_viridis_d(option = "B", end = .8) +
  scale_fill_viridis_d(option = "B", end = .8) +
  theme(legend.position = "none", axis.text.x = element_text(size = 12)) +
  scale_x_date(minor_breaks = "month", date_labels = "%b %y") +
  scale_y_continuous(expand = expansion(mult = c(0, .05))) +
  labs(x = "Date", y = "Reported COVID-19 cases\n (thousands)")
```


## `{epipredict}`

### + Framework for customizing from modular components.

1. Preprocessor: do things to the data before model training
2. Trainer: train a model on data, resulting in an object
3. Predictor: make predictions, using a fitted model object
4. Postprocessor: do things to the predictions before returning

. . .

A very specialized plug-in to [`{tidymodels}`](https://tidymodels.org)


## Making dumb (but useful!) forecasts in epidemiology

* Suppose we want to predict new hospitalizations $y$, $h$ days ahead, at many locations $j$.

* We're going to make a new forecast each week.

::: {.r-stack}
::: {.fragment .fade-in-then-out}

### Flatline forecaster

For each location, predict 
$$\hat{y}_{j,i+h} = y_{j,i}$$
:::

::: {.fragment}

### AR forecaster

Use an AR model with some covariates, for example:
$$\hat{y}_{j,i+1} = \mu + a_0 y_{j,i} + a_7 y_{j,i-7} + b_0 x_{j,i} + b_7 x_{j,i-7}$$
:::
:::

## `{epipredict}` 
### A forecasting framework

* Flatline forecaster
* AR-type models
* Backtest using the versioned data
* Easily create features
* Quickly pivot to new tasks
* Highly customizable for advanced users 

## `{epipredict}`

### Canned forecasters that work out of the box.
    
You can do a limited amount of customization. 

We currently provide:

- Baseline flat-line forecaster
- Autoregressive-type forecaster
- Autoregressive-type classifier


## Basic autoregressive forecaster

* Predict `death_rate`, 1 week ahead, with `0,7,14` day lags of `cases` and `deaths`. 
* Use `lm` for estimation. Also create "intervals".

```{r}
#| echo: true
#| warning: false
library(epipredict)
jhu <- case_death_rate_subset # grab some built-in data
canned <- arx_forecaster(
  epi_data = jhu, 
  outcome = "death_rate", 
  predictors = c("case_rate", "death_rate")
)
```

The output is a model object that could be reused in the future, along with the predictions for 7 days from now.

## Adjust lots of built-in options

```{r}
#| echo: true
#| eval: false
#| code-line-numbers: "|4|5|7|8|9|10"
rf <- arx_forecaster(
  epi_data = jhu, 
  outcome = "death_rate", 
  predictors = c("case_rate", "death_rate", "fb-survey"),
  trainer = parsnip::rand_forest(mode = "regression"), # use ranger
  args_list = arx_args_list(
    ahead = 14, # 2-week horizon
    lags = list(c(0:4, 7, 14), c(0, 7, 14), c(0:7, 14)), # bunch of lags
    levels = c(0.01, 0.025, 1:19/20, 0.975, 0.99), # 23 ForecastHub quantiles
    quantile_by_key = "geo_value" # vary q-forecasts by location
  )
)
```



## Do (almost) anything manually

```{r}
#| echo: true
#| eval: false
#| code-line-numbers: "1-6|8-13|15-17|19-26"
# A preprocessing "recipe" that turns raw data into features / response
r <- epi_recipe(jhu) %>%
  step_epi_lag(case_rate, lag = c(0, 1, 2, 3, 7, 14)) %>%
  step_epi_lag(death_rate, lag = c(0, 7, 14)) %>%
  step_epi_ahead(death_rate, ahead = 14) %>%
  step_epi_naomit()

# A postprocessing routine describing what to do to the predictions
f <- frosting() %>%
  layer_predict() %>%
  layer_threshold(.pred, lower = 0) %>% # predictions/intervals should be non-negative
  layer_add_target_date(target_date = max(jhu$time_value) + 14) %>%
  layer_add_forecast_date(forecast_date = max(jhu$time_value))

# Bundle up the preprocessor, training engine, and postprocessor
# We use quantile regression
ewf <- epi_workflow(r, quantile_reg(tau = c(.1, .5, .9)), f)

# Fit it to data (we could fit this to ANY data that has the same format)
trained_ewf <- ewf %>% fit(jhu)

# examines the recipe to determine what we need to make the prediction
latest <- get_test_data(r, jhu)

# we could make predictions using the same model on ANY test data
preds <- trained_ewf %>% predict(new_data = latest)
```


# Pivot to some online examples

[Long book on `{epipredict}`](https://dajmcdon.github.io/cdph-vignette/index.html), in progress...



## Packages are under active development {.smaller}


### Thanks:

```{r qr-codes}
#| include: false
#| fig-format: png
qrdat <- function(text, ecl = c("L", "M", "Q", "H")) {
  x <- qrcode::qr_code(text, ecl)
  n <- nrow(x)
  s <- seq_len(n)
  tib <- tidyr::expand_grid(x = s, y = rev(s))
  tib$z <- c(x)
  tib
}
qr1 <- qrdat("https://cmu-delphi.github.io/epiprocess/")
qr2 <- qrdat("https://cmu-delphi.github.io/epipredict/")
ggplot(qr1, aes(x, y, fill = z)) +
  geom_raster() +
  ggtitle("{epiprocess}") +
  coord_equal(expand = FALSE) +
  scale_fill_manual(values = c("white", "black"), guide = "none") +
  theme_void(base_size = 18) +
  theme(plot.title = element_text(hjust = .5))
ggplot(qr2, aes(x, y, fill = z)) +
  geom_raster() +
  labs(title = "{epipredict}") +
  coord_equal(expand = FALSE) +
  scale_fill_manual(values = c("white", "black"), guide = "none") +
  theme_void(base_size = 18) +
  theme(plot.title = element_text(hjust = .5))
```

:::: {.columns}
::: {.column width="50%"}
- The whole [CMU Delphi Team](https://delphi.cmu.edu/about/team/) (across many institutions)
- Optum/UnitedHealthcare, Change Healthcare.
- Google, Facebook, Amazon Web Services.
- Quidel, SafeGraph, Qualtrics.
- Centers for Disease Control and Prevention.
- Council of State and Territorial Epidemiologists
:::

::: {.column width="50%"}

![](gfx/qr-epiprocess.png){width="300px"}
![](gfx/qr-epipredict.png){width="300px"}

:::

::::

::: {layout-row=1 fig-align="center"}
![](gfx/delphi.jpg){height="100px"}
![](gfx/berkeley.jpg){height="100px"}
![](gfx/cmu.jpg){height="100px"}
![](gfx/ubc.jpg){width="250px"}
![](gfx/usc.jpg){width="250px"}
![](gfx/stanford.jpg){width="250px"}
:::


